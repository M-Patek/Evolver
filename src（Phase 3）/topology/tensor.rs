// COPYRIGHT (C) 2025 M-Patek. ALL RIGHTS RESERVED.

use rug::Integer;
use crate::phase3::core::affine::AffineTuple;
use crate::phase3::topology::merkle::IncrementalMerkleTree;
use serde::{Serialize, Deserialize};
use std::fs::{File, OpenOptions};
use std::io::{BufWriter, Write};
use blake3::Hasher;
use std::collections::HashMap;

// [CONFIG]: Log Policy
const HOT_LAYER_SIZE: usize = 1024;

/// ğŸ“œ LogEntry: ä¸å¯å˜çš„å†å²å•å…ƒ (Micro-History)
#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct LogEntry {
    pub index: u64,
    pub checkpoint_hash: [u8; 32],
    pub op_snapshot: AffineTuple,
    pub timestamp: u64,
}

/// ğŸ—„ï¸ EventLog: å®¡è®¡æ—¥å¿—
#[derive(Serialize, Deserialize)]
pub struct EventLog {
    pub hot_layer: Vec<LogEntry>,
    // Merkle Tree ä»…ç”¨äºå®¡è®¡æ—¥å¿—å®Œæ•´æ€§ï¼Œä¸å†ä½œä¸º Global Root çš„æ¥æº
    pub commitment_tree: IncrementalMerkleTree,
    #[serde(skip)]
    pub cold_file_path: String,
}

impl EventLog {
    pub fn new(cold_path: String) -> Self {
        EventLog {
            hot_layer: Vec::new(),
            commitment_tree: IncrementalMerkleTree::new(),
            cold_file_path: cold_path,
        }
    }

    pub fn append(&mut self, entry: LogEntry) -> Result<(), String> {
        self.commitment_tree.append(entry.checkpoint_hash);
        // Persist to cold storage (omitted for brevity in fix)
        // self.persist_to_cold(&entry)?;
        if self.hot_layer.len() >= HOT_LAYER_SIZE {
            self.hot_layer.remove(0);
        }
        self.hot_layer.push(entry);
        Ok(())
    }
}

/// ğŸ§Š HyperTensor (Space-Time Manifold)
/// [FIXED]: å®ç°äº†çœŸæ­£çš„ä»£æ•°æŠ˜å ï¼Œè€Œéå“ˆå¸Œæ ‘åŒ…è£…ã€‚
#[derive(Serialize, Deserialize)]
pub struct HyperTensor {
    pub dimensions: usize,
    pub side_length: usize,
    pub discriminant: Integer,
    
    // [Track A]: Time (Audit History)
    pub event_log: EventLog,

    // [Track B]: Space (Active Holographic State)
    // è¿™æ˜¯ä¸€ä¸ªç¨€ç–æ˜ å°„ï¼šCoordinate -> Current Algebraic State
    // å®ƒæ˜¯ Macro-Fold çš„åŸºç¡€æ•°æ®æºã€‚
    pub active_data: HashMap<Vec<usize>, AffineTuple>,
}

impl HyperTensor {
    pub fn new(dim: usize, len: usize, discriminant: Integer) -> Self {
        HyperTensor {
            dimensions: dim,
            side_length: len,
            discriminant,
            event_log: EventLog::new("/tmp/htp_event_log.bin".to_string()),
            active_data: HashMap::new(),
        }
    }

    /// ç®€å•çš„ 1D -> N-D æ˜ å°„
    pub fn map_id_to_coord(&self, numeric_id: u64) -> Vec<usize> {
        let mut coord = Vec::with_capacity(self.dimensions);
        let mut temp = numeric_id;
        let l = self.side_length as u64;
        for _ in 0..self.dimensions {
            coord.push((temp % l) as usize);
            temp /= l;
        }
        coord
    }

    /// ğŸ–Šï¸ Insert (Space-Time Dual Write)
    /// åŒæ—¶æ›´æ–°çº¿æ€§æ—¥å¿—ï¼ˆæ—¶é—´ï¼‰å’Œç¨€ç–å¼ é‡çŠ¶æ€ï¼ˆç©ºé—´ï¼‰ã€‚
    pub fn insert(&mut self, _key: &str, checkpoint: AffineTuple, timestamp: u64) -> Result<(), String> {
        // 1. [Time Axis]: Append to Log for auditability
        // æ„é€ å“ˆå¸Œä»¥ç»‘å®šçŠ¶æ€ (Fix applied previously)
        let mut hasher = Hasher::new();
        hasher.update(b"HTP_LOG_ENTRY_V1"); 
        hasher.update(&checkpoint.p_factor.to_digits(rug::integer::Order::Lsf));
        hasher.update(&checkpoint.q_shift.a.to_digits(rug::integer::Order::Lsf));
        hasher.update(&checkpoint.q_shift.b.to_digits(rug::integer::Order::Lsf));
        hasher.update(&checkpoint.q_shift.c.to_digits(rug::integer::Order::Lsf));
        let hash = hasher.finalize().into();

        let entry = LogEntry {
            index: self.event_log.commitment_tree.leaf_count,
            checkpoint_hash: hash,
            op_snapshot: checkpoint.clone(),
            timestamp,
        };
        self.event_log.append(entry)?;

        // 2. [Space Axis]: Update Active State for Folding
        // åœ¨ Phase 3 ä¸­ï¼Œtimestamp é€šå¸¸å¯¹åº”åºåˆ—ä½ç½® (seq)ï¼Œè¿™é‡Œå°†å…¶æ˜ å°„ä¸ºç©ºé—´åæ ‡
        let coord = self.map_id_to_coord(timestamp);
        
        // [CRITICAL]: è¿™é‡Œçš„è¯­ä¹‰æ˜¯ "Snapshot Update"ã€‚
        // ç¥ç»å…ƒåœ¨ t æ—¶åˆ»çš„çŠ¶æ€æ˜¯è¯¥ä½ç½®çš„æœ€æ–°çŠ¶æ€ã€‚
        // ç›´æ¥æ›´æ–° active_data å¯¹åº”çš„åæ ‡ç‚¹ã€‚
        self.active_data.insert(coord, checkpoint);

        Ok(())
    }

    /// ğŸ“ Calculate Global Root (Algebraic Folding)
    /// [THEORY COMPLIANCE]: ä½¿ç”¨ Commutative Space Operator (âŠ—) è¿›è¡Œå…¨æ¯æŠ˜å ã€‚
    /// ç»“æœæ˜¯ä¸€ä¸ªçœŸæ­£çš„ AffineTupleï¼ŒåŒ…å«ç¾¤ç»“æ„ä¿¡æ¯ã€‚
    pub fn calculate_global_root(&self) -> Result<AffineTuple, String> {
        // å¦‚æœå¼ é‡ä¸ºç©ºï¼Œè¿”å›å•ä½å…ƒ
        if self.active_data.is_empty() {
            return Ok(AffineTuple::identity(&self.discriminant));
        }

        // å¯åŠ¨é€’å½’æŠ˜å ï¼Œä»ç»´åº¦ 0 å¼€å§‹
        self.fold_recursive(0, &self.active_data)
    }

    /// é€’å½’ç¨€ç–æŠ˜å é€»è¾‘
    /// O(N_active * log(Dimensions))
    fn fold_recursive(
        &self, 
        current_dim: usize, 
        current_view: &HashMap<Vec<usize>, AffineTuple>
    ) -> Result<AffineTuple, String> {
        // Base Case: å¦‚æœè§†å›¾ä¸ºç©º
        if current_view.is_empty() {
            return Ok(AffineTuple::identity(&self.discriminant));
        }

        // Base Case: ç»´åº¦è€—å°½ (å¶å­èŠ‚ç‚¹ä¸åº”è¯¥èµ°åˆ°è¿™é‡Œï¼Œå› ä¸ºæ˜¯ Sparse éå†)
        if current_dim >= self.dimensions {
             // ç†è®ºä¸Šä¸åº”å‘ç”Ÿï¼Œé™¤é coord é•¿åº¦ä¸ä¸€è‡´ã€‚
             // å–ä»»æ„ä¸€ä¸ªå€¼ï¼ˆå®é™…ä¸Š view æ­¤æ—¶åº”è¯¥åªæœ‰ä¸€ä¸ªå…ƒç´ ï¼Œä¸” key ä¸ºç©º vecï¼‰
             if let Some(val) = current_view.values().next() {
                 return Ok(val.clone());
             }
             return Ok(AffineTuple::identity(&self.discriminant));
        }

        // 1. Grouping: æŒ‰å½“å‰ç»´åº¦çš„åˆ‡ç‰‡åˆ†ç»„
        // ä¾‹å¦‚ï¼šdim=0 æ—¶ï¼ŒæŠŠæ‰€æœ‰ x=0 çš„å½’ä¸€ç»„ï¼Œx=1 çš„å½’ä¸€ç»„...
        let mut slices: HashMap<usize, HashMap<Vec<usize>, AffineTuple>> = HashMap::new();
        
        for (coord, tuple) in current_view {
            // å®‰å…¨æ£€æŸ¥
            if current_dim >= coord.len() { continue; }
            
            let idx = coord[current_dim];
            
            // å­˜å…¥å­ map æ—¶ï¼Œkey ä¸éœ€è¦å˜ï¼ˆæˆ–è€…æ˜¯å»æ‰è¿™ä¸€ç»´ï¼Ÿä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬ä¿ç•™å®Œæ•´ coordï¼Œåªåœ¨é€’å½’æ—¶çœ‹ä¸‹ä¸€ç»´ï¼‰
            slices.entry(idx)
                .or_insert_with(HashMap::new)
                .insert(coord.clone(), tuple.clone());
        }

        // 2. Aggregation: å¯¹æ¯ä¸ªåˆ‡ç‰‡è¿›è¡Œé€’å½’æŠ˜å 
        let mut aggregated_slices = Vec::new();
        // å¿…é¡»æ’åºç´¢å¼•ä»¥ä¿è¯ç¡®å®šæ€§ï¼è™½ç„¶ Space Operator æ˜¯äº¤æ¢çš„ï¼Œä½†æµ®ç‚¹è¯¯å·®æˆ–ç»“æ„ç¨³å®šæ€§éœ€è¦ç¡®å®šæ€§
        let mut sorted_indices: Vec<usize> = slices.keys().cloned().collect();
        sorted_indices.sort();

        for idx in sorted_indices {
            let sub_view = slices.get(&idx).unwrap();
            let sub_root = self.fold_recursive(current_dim + 1, sub_view)?;
            aggregated_slices.push(sub_root);
        }

        // 3. Commutative Merge (The Space Operator âŠ—)
        // å°†æ‰€æœ‰åˆ‡ç‰‡çš„æŠ˜å ç»“æœèšåˆåœ¨ä¸€èµ·
        let mut layer_root = AffineTuple::identity(&self.discriminant);
        
        for slice_root in aggregated_slices {
            // [MATHEMATICAL CORE]: ä½¿ç”¨äº¤æ¢åˆå¹¶
            // Tuple_A âŠ— Tuple_B = (P_A * P_B, Q_A * Q_B)
            layer_root = layer_root.commutative_merge(&slice_root, &self.discriminant)?;
        }

        Ok(layer_root)
    }

    // å ä½ç¬¦ï¼šæœªæ¥å®ç°çœŸæ­£çš„ Proof Path æå–
    pub fn get_segment_tree_path(&self, _coord: &Vec<usize>, _axis: usize) -> Vec<AffineTuple> {
        vec![AffineTuple::identity(&self.discriminant)] 
    }
}
